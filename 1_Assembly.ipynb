{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aecedc5e-495f-4ca3-bee5-1b96be2df467",
   "metadata": {},
   "source": [
    "# Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a0876-91b1-491e-b15c-fa67d8a5bc60",
   "metadata": {},
   "source": [
    "Reads have been run through QC and trimming (Col_qc.sh). Continuing on with SAMPLEID_R1/2_001_val_2.fq.gz files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c4d818-a17e-4e50-8634-d5d4386566cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTALLATION envs\n",
    "module load conda/latest\n",
    "conda create -n assembly\n",
    "conda activate assembly\n",
    "conda install -c bioconda megahit\n",
    "conda install -c bioconda quast python=2.7\n",
    "\n",
    "module load conda/latest\n",
    "conda create -y --name anvio-8 python=3.10\n",
    "conda activate anvio-8\n",
    "conda install -y -c conda-forge -c bioconda python=3.10 \\\n",
    "        sqlite prodigal idba mcl muscle=3.8.1551 famsa hmmer diamond \\\n",
    "        blast megahit spades bowtie2 bwa graphviz \"samtools>=1.9\" \\\n",
    "        trimal iqtree trnascan-se fasttree vmatch r-base r-tidyverse \\\n",
    "        r-optparse r-stringi r-magrittr bioconductor-qvalue meme ghostscript \\\n",
    "        nodejs\n",
    "curl -L https://github.com/merenlab/anvio/releases/download/v8/anvio-8.tar.gz \\\n",
    "        --output anvio-8.tar.gz\n",
    "pip install anvio-8.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e38223e-40c9-49b4-b340-c85b5e39516e",
   "metadata": {},
   "source": [
    "Documentation for anvi'o https://anvio.org/install/linux/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377a924-4976-4198-b81f-30859603bd4f",
   "metadata": {},
   "source": [
    "Developing from Brooke's scripts, with these steps:\n",
    "\n",
    "1)remove host from sample reads \\\n",
    "2)remove symbiont and human seqs using fastq screen \\\n",
    "3)concatenate all f and r seqs into single file (1 for f, 1 for r) \\\n",
    "4)ASSEMBLE reads into contigs (contiguous sequence - joins them together based on read overlap, and ensures there are no gaps - larger portions of genomes if not all are now together in one sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed19c2-f37b-42de-9472-eec9a08b99bb",
   "metadata": {},
   "source": [
    "## Step 1: Host removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90369d2d-91d6-4e17-8e4d-71017b5597e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=180G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/slurm-removal-%j.out  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate anvio-8\n",
    "\n",
    "# 1)remove host from sample reads\n",
    "#set general parameters:\n",
    "SAMPLENAME=\"dlab\"\n",
    "SAMPLELIST=\"032024_dlab_sampleids.txt\"\n",
    "RAWREADSPATH='/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/trimmed/dlab'\n",
    "READSPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}/host_removed\"\n",
    "mkdir -p $READSPATH\n",
    "EXTRAFILESPATH=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL_files/host_removal/${SAMPLENAME}\"\n",
    "mkdir -p $EXTRAFILESPATH\n",
    "LISTPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/\"\n",
    "#set step parameters \n",
    "GENOME=\"Cnat\"\n",
    "INPUTPATH=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/${GENOME}_genome\"\n",
    "INDEX=\"${GENOME}_DB\"\n",
    "\n",
    "#build a bowtie2 index from a known genome (using C. natans genome, indexes already built)\n",
    "#bowtie2-build $INPUTPATH/Cnat_genomic.fna $INPUTPATH/\"$INDEX\"\n",
    "\n",
    "#loop through samples\n",
    "while IFS= read -r SAMPLEID; do\n",
    "        echo \"starting on $SAMPLEID\"\n",
    "#re-align reads back to the index\n",
    "bowtie2 -p 8 -x $INPUTPATH/$INDEX -1 \"$RAWREADSPATH\"/\"${SAMPLEID}_R1_001_val_1.fq.gz\" -2 \"$RAWREADSPATH\"/\"${SAMPLEID}_R2_001_val_2.fq.gz\" -S $EXTRAFILESPATH/\"${SAMPLEID}\"_mapped_and_unmapped.sam\n",
    "#convert sam file from bowtie to a bam file for processing\n",
    "samtools view -bS $EXTRAFILESPATH/\"${SAMPLEID}\"_mapped_and_unmapped.sam > $EXTRAFILESPATH/\"${SAMPLEID}\"_mapped_and_unmapped.bam\n",
    "#extract only the reads of which both do not match against the host genome\n",
    "samtools view -b -f 12 -F 256 $EXTRAFILESPATH/\"${SAMPLEID}\"_mapped_and_unmapped.bam > $EXTRAFILESPATH/\"${SAMPLEID}\"_bothReadsUnmapped.bam\n",
    "# sorts the file so both mates are together and then extracts them back as .fastq.gz files\n",
    "samtools sort -n -m 5G -@ 2 $EXTRAFILESPATH/\"${SAMPLEID}\"_bothReadsUnmapped.bam -o $EXTRAFILESPATH/\"${SAMPLEID}\"_bothReadsUnmapped_sorted.bam\n",
    "samtools fastq -c 6 -@ 8 $EXTRAFILESPATH/\"${SAMPLEID}\"_bothReadsUnmapped_sorted.bam \\\n",
    "    -1 $READSPATH/\"${SAMPLEID}\"_host_removed_R1.fastq.gz \\\n",
    "    -2 $READSPATH/\"${SAMPLEID}\"_host_removed_R2.fastq.gz \\\n",
    "    -0 /dev/null -s /dev/null -n\n",
    " if [ $? -eq 0 ]; then\n",
    "        echo \"host removal completed successfully for sample: $SAMPLEID\"\n",
    "    else\n",
    "        echo \"host removal encountered an error for sample: $SAMPLEID\"\n",
    "        exit 1  \n",
    "    fi\n",
    "done < \"$LISTPATH/${SAMPLELIST}\"\n",
    "rm -rf $EXTRAFILESPATH/*.sam\n",
    "conda deactivate\n",
    "echo \"Host removal: All samples processed successfully.\"\n",
    "\n",
    "# JOB-ID: \n",
    "# bash script file name:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d54e9d-a312-4744-b434-93cdb206a1f2",
   "metadata": {},
   "source": [
    "Outputs:\n",
    "\n",
    "The SAMs, sorted and unsorted BAMs are in /project.../COL_files/host_removal_mcav/ for storage reasons \\\n",
    "The host-removed fastq.gz files are in /work/.../COL/assembly/mcav/ for next step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a61437-3d85-43c6-b049-ef353eb3715e",
   "metadata": {},
   "source": [
    "## Step 2: Fastq-screen for symbiont and human seq removal\n",
    "https://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd62cbb-0c4d-4877-bdd5-7a878567c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installation\n",
    "module load conda/latest\n",
    "conda activate assembly\n",
    "conda install -c bioconda fastq-screen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a796d12-4e72-4cd5-b31e-aa69ad71634f",
   "metadata": {},
   "source": [
    "*Made the fastq-screen.conf file (tells the program what aligner to use and where all the databases are)* \\\n",
    "**fastq_screen.conf file below** \\\n",
    "I added more symbiont databases to it and used a quick bowtie script to index the new genomes I added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34204080-0a62-41ab-9629-5cdfc5f9f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=50G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/slurm-index-%j.out  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate assembly\n",
    "\n",
    "#build a bowtie2 index \n",
    "bowtie2-build --threads 20 /project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/Genomes/GCA_963969995.1/GCA_963969995.1_Durusdinium_trenchii_SCF082.fna /project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_963969995.1_index\n",
    "\n",
    "bowtie2-build /project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/Genomes/GCA_947184155.2/GCA_947184155.2_Cgoreaui_SCF055-01_v2.1_genomic.fna /project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_947184155.2_index\n",
    "\n",
    "conda deactivate\n",
    "\n",
    "# Job ID:\n",
    "# bash script file name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc88e0b-b732-477d-9e05-d1f874ce1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## Bowtie, Bowtie 2 or BWA #\n",
    "############################\n",
    "## If the Bowtie, Bowtie 2 or BWA binary is not in your PATH, you can set \n",
    "## this value to tell the program where to find your chosen aligner.  Uncomment \n",
    "## the relevant line below and set the appropriate location.  Please note, \n",
    "## this path should INCLUDE the executable filename.\n",
    "\n",
    "#BOWTIE\t/usr/local/bin/bowtie/bowtie\n",
    "BOWTIE2 /home/nikea_ulrich_uml_edu/.conda/envs/assembly/bin/bowtie2\n",
    "#BWA /usr/local/bwa/bwa\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "## Bismark (for bisulfite sequencing only) #\n",
    "############################################\n",
    "## If the Bismark binary is not in your PATH then you can set this value to \n",
    "## tell the program where to find it.  Uncomment the line below and set the \n",
    "## appropriate location. Please note, this path should INCLUDE the executable \n",
    "## filename.\n",
    "\n",
    "#BISMARK\t/usr/local/bin/bismark/bismark\n",
    "\n",
    "\n",
    "\n",
    "############\n",
    "## Threads #\n",
    "############\n",
    "## Genome aligners can be made to run across multiple CPU cores to speed up \n",
    "## searches.  Set this value to the number of cores you want for mapping reads.\n",
    "\n",
    "THREADS\t\t12\n",
    "\n",
    "\n",
    "\n",
    "##############\n",
    "## DATABASES #\n",
    "##############\n",
    "## This section enables you to configure multiple genomes databases (aligner index \n",
    "## files) to search against in your screen.  For each genome you need to provide a \n",
    "## database name (which can't contain spaces) and the location of the aligner index \n",
    "## files.\n",
    "##\n",
    "## The path to the index files SHOULD INCLUDE THE BASENAME of the index, e.g:\n",
    "## /data/public/Genomes/Human_Bowtie/GRCh37/Homo_sapiens.GRCh37\n",
    "## Thus, the index files (Homo_sapiens.GRCh37.1.bt2, Homo_sapiens.GRCh37.2.bt2, etc.) \n",
    "## are found in a folder named 'GRCh37'.\n",
    "##\n",
    "## If, for example, the Bowtie, Bowtie2 and BWA indices of a given genome reside in \n",
    "## the SAME FOLDER, a SINLGE path may be provided to ALL the of indices.  The index \n",
    "## used will be the one compatible with the chosen aligner (as specified using the \n",
    "## --aligner flag).  \n",
    "##\n",
    "## The entries shown below are only suggested examples, you can add as many DATABASE \n",
    "## sections as required, and you can comment out or remove as many of the existing \n",
    "## entries as desired.  We suggest including genomes and sequences that may be sources \n",
    "## of contamination either because they where run on your sequencer previously, or may \n",
    "## have contaminated your sample during the library preparation step.\n",
    "##\n",
    "## Human - sequences available from\n",
    "## ftp://ftp.ensembl.org/pub/current/fasta/homo_sapiens/dna/\n",
    "## (Kraken2 RefSeq db)\n",
    "DATABASE\tHuman\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/ref_databases/standard/library/human/index\n",
    "##\n",
    "## added more databases and updated a few listed here with their updated assemblies 12.11.2024\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont1\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/Durusdinium_trenchii_indexed\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont2\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_000507305.1_index\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont3\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_001939145.1_index\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont4\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_003297005.1_index\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont5\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_009767595.1_index\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont6\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_018327485.1_index\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont7\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_905221635.1_index\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont8\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_947184155.2_index\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont9\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_003297045.1_index\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont10\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_905231905.1_index\n",
    "## Symbionts\n",
    "DATABASE\tSymbiont11\t/project/pi_sarah_gignouxwolfsohn_uml_edu/Reference_genomes/symbionts/indexed/GCA_905231915.1_index\n",
    "##\n",
    "## Ecoli- sequence available from EMBL accession U00096.2\n",
    "#DATABASE\tEcoli\t/data/public/Genomes/Ecoli/Ecoli\n",
    "##\n",
    "## PhiX - sequence available from Refseq accession NC_001422.1\n",
    "#DATABASE\tPhiX\t/data/public/Genomes/PhiX/phi_plus_SNPs\n",
    "##\n",
    "## Adapters - sequence derived from the FastQC contaminats file found at: www.bioinformatics.babraham.ac.uk/projects/fastqc\n",
    "#DATABASE\tAdapters\t/data/public/Genomes/Contaminants/Contaminants\n",
    "##\n",
    "## Vector - Sequence taken from the UniVec database\n",
    "## http://www.ncbi.nlm.nih.gov/VecScreen/UniVec.html\n",
    "#DATABASE\tVectors\t\t/data/public/Genomes/Vectors/Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f8f13-c874-48aa-83a1-d84dd5d8216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moved the conf file to the fastq screen directory in the assembly environment\n",
    "mv fastq_screen.conf /home/nikea_ulrich_uml_edu/.conda/envs/assembly/share/fastq-screen-0.16.0-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ff5b5-6ee1-4e29-9b9a-cfd03acb0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=180G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/mcav/slurm-HSremoval-%j.out  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate assembly\n",
    "\n",
    "# 2)remove symbiont and human seqs using fastq screen \n",
    "SAMPLENAME=\"mcav\"\n",
    "SAMPLELIST=\"032024_mcav_sampleids.txt\" \n",
    "READSPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}/host_removed\"\n",
    "LISTPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/\"\n",
    "\n",
    "FASTQSCREEN='/home/nikea_ulrich_uml_edu/.conda/envs/assembly/share/fastq-screen-0.16.0-0'\n",
    "OUTPUTDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}/final_reads_filtered\"\n",
    "\n",
    "mkdir -p \"$OUTPUTDIR\"\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"Error: Failed to create output directory $OUTPUTDIR\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "while IFS= read -r SAMPLEID; do\n",
    "$FASTQSCREEN/fastq_screen --nohits --aligner bowtie2 --conf $FASTQSCREEN/fastq_screen.conf --outdir $OUTPUTDIR \\\n",
    "$READSPATH/\"${SAMPLEID}\"_host_removed_R1.fastq.gz $READSPATH/\"${SAMPLEID}\"_host_removed_R2.fastq.gz;\n",
    " if [ $? -eq 0 ]; then\n",
    "        echo \"fastq_screen completed successfully for sample: $SAMPLEID\"\n",
    "    else\n",
    "        echo \"fastq_screen encountered an error for sample: $SAMPLEID\"\n",
    "        exit 1\n",
    "    fi\n",
    "# --nohits = output reads do not map to any genomes\n",
    "done < \"$LISTPATH/${SAMPLELIST}\"\n",
    "conda deactivate\n",
    "echo \"Symbiont, host removal: All samples processed successfully.\"\n",
    "\n",
    "# JOB-ID:\n",
    "# bash script file name:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a6369-5969-4f01-8310-81b71834c2f4",
   "metadata": {},
   "source": [
    "*note*- to find path for bowtie2 aligner for fastq_screen.conf, I activated the assembly conda environment and did the command: bowtie2 --version \\\n",
    "This gives you the path to put in the conf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8255cb-8dff-423e-846e-015f8f3126fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ran multiqc in each directory to combine fastq-screen results for visualization\n",
    "module load conda/latest\n",
    "conda activate multiqc \n",
    "# in directory with fastq-screen output: /final_reads_filtered\n",
    "multiqc .\n",
    "conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8e80e0-866c-4407-9b89-04a22e898968",
   "metadata": {},
   "source": [
    "## Steps 3 & 4 Concatenating reads and assembling into contigs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9999056e-055c-4ca4-85e6-3117b219806a",
   "metadata": {},
   "source": [
    "Filtering paired-end reads files separately will generate files with un-paired reads e.g. a read may be present in File1, but its corresponding pair may not be found in File2. Also, the order of the reads in processed files may not correspond to on another. Consequently, the resulting file pairs will need processing after filtering with FastQ Screen.\n",
    "\n",
    "https://jgi.doe.gov/data-and-tools/software-tools/bbtools/bb-tools-user-guide/repair-guide/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e67bc7-8701-41f2-a751-c5e8ce38c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTALLATION\n",
    "module load conda/latest\n",
    "conda activate assembly\n",
    "conda install -c bioconda bbmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25bd0e1-e190-469f-b1e5-2c481cbe0cbf",
   "metadata": {},
   "source": [
    "Run this repair script before concatenating files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69f9a7-24b7-4516-9b38-c0a9251f4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=180G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/pstr/slurm-repair-%j.out  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate assembly\n",
    "\n",
    "\n",
    "SAMPLENAME=\"pstr\"\n",
    "SAMPLELIST=\"032024_pstr_sampleids.txt\" \n",
    "READSPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}/final_reads_filtered\"\n",
    "LISTPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/\"\n",
    "OUTDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}/repaired\"\n",
    "mkdir -p \"$OUTDIR\"\n",
    "\n",
    "#Lets try this! Using repair.sh script from:https://jgi.doe.gov/data-and-tools/software-tools/bbtools/bb-tools-user-guide/repair-guide/\n",
    "while IFS= read -r SAMPLEID; do\n",
    "\n",
    "repair.sh in1=$READSPATH/\"${SAMPLEID}\"_host_removed_R1.tagged_filter.fastq.gz in2=$READSPATH/\"${SAMPLEID}\"_host_removed_R2.tagged_filter.fastq.gz \\\n",
    "out1=$OUTDIR/\"${SAMPLEID}\"_host_removed_R1.tagged_filter_ready.fastq.gz out2=$OUTDIR/\"${SAMPLEID}\"_host_removed_R2.tagged_filter_ready.fastq.gz \\\n",
    "outs=$OUTDIR/\"${SAMPLEID}\"singletons.fq repair;\n",
    " if [ $? -eq 0 ]; then\n",
    "        echo \"repair completed successfully for sample: $SAMPLEID\"\n",
    "    else\n",
    "        echo \"repair encountered an error for sample: $SAMPLEID\"\n",
    "        exit 1\n",
    "    fi\n",
    "done < \"$LISTPATH/${SAMPLELIST}\"\n",
    "\n",
    "conda deactivate\n",
    "echo \"Repair: All samples processed successfully.\"\n",
    "\n",
    "# JOB-ID:\n",
    "# bash script file name: bbtools_repair.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d533d-09b3-48b3-9672-c3ab18e9bca2",
   "metadata": {},
   "source": [
    "Now concatenate F and R reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606d968-a326-45f1-a7cc-c1313a543e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=180G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/pstr/slurm-cat-%j.out  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate assembly\n",
    "\n",
    "SAMPLENAME=\"pstr\"\n",
    "SAMPLELIST=\"032024_pstr_sampleids.txt\" \n",
    "READSPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}/repaired\"\n",
    "LISTPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/\"\n",
    "WORKDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}\"\n",
    "\n",
    "# 3)CONCATETATE all f and r seqs into single file (1 for f, 1 for r)\n",
    "# Read the sample IDs from the file\n",
    "while IFS= read -r SAMPLEID; do\n",
    "    # Construct the file paths for forward and reverse reads\n",
    "    FORWARD_READ=\"$READSPATH/${SAMPLEID}_host_removed_R1.tagged_filter_ready.fastq.gz\"\n",
    "    REVERSE_READ=\"$READSPATH/${SAMPLEID}_host_removed_R2.tagged_filter_ready.fastq.gz\"\n",
    "\n",
    "    # Check if the files exist before concatenating\n",
    "    if [ -e \"$FORWARD_READ\" ]; then\n",
    "        cat \"$FORWARD_READ\" >> \"$WORKDIR/${SAMPLENAME}_reads_R1_ALL.fastq.gz\"\n",
    "    else\n",
    "        echo \"Forward read file not found for sample $SAMPLEID\"\n",
    "    fi\n",
    "\n",
    "    if [ -e \"$REVERSE_READ\" ]; then\n",
    "        cat \"$REVERSE_READ\" >> \"$WORKDIR/${SAMPLENAME}_reads_R2_ALL.fastq.gz\"\n",
    "    else\n",
    "        echo \"Reverse read file not found for sample $SAMPLEID\"\n",
    "    fi\n",
    "done < \"$LISTPATH/${SAMPLELIST}\"\n",
    "\n",
    "conda deactivate\n",
    "echo \"Concatenation completed!\"\n",
    "\n",
    "# JOB-ID:\n",
    "# bash script file name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114dbbf-7f85-447a-a778-62bdf2e6c7f3",
   "metadata": {},
   "source": [
    "Then assemble with megahit (https://github.com/voutcn/megahit/wiki/An-example-of-real-assembly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b73f0a9-5da5-46ac-a653-1f85a7e2580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=180G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 48:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/pstr/slurm-assembly-%j.out  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate assembly\n",
    "\n",
    "SAMPLENAME=\"pstr\"\n",
    "SAMPLELIST=\"032024_pstr_sampleids.txt\" \n",
    "LISTPATH=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/\"\n",
    "WORKDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}\"\n",
    "\n",
    "# 4)ASSEMBLE reads into contigs (contiguous sequence - joins them together based on read overlap, and ensures there are no gaps\n",
    "megahit --presets meta-large \\\n",
    "-1 \"$WORKDIR\"/\"$SAMPLENAME\"_reads_R1_ALL.fastq.gz \\\n",
    "-2 \"$WORKDIR\"/\"$SAMPLENAME\"_reads_R2_ALL.fastq.gz \\\n",
    "--keep-tmp-files \\\n",
    "-o $WORKDIR/megahit_assembly --out-prefix $SAMPLENAME \\\n",
    "#this one has to make the directory; will fail if it already exists\n",
    "\n",
    "conda deactivate\n",
    "echo \"Assembly completed!\"\n",
    "\n",
    "# JOB-ID: \n",
    "# bash script file name:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a027b40a-82c5-422a-bb12-bd3d95730abe",
   "metadata": {},
   "source": [
    "## Quality check co-assembly\n",
    "Metaquast: https://github.com/ablab/quast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86270d97-071d-4540-b05b-1c78331655bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 24  # Number of Cores per Task\n",
    "#SBATCH --mem=50G  # Requested Memory\n",
    "#SBATCH -p cpu  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/pstr/slurm-metaquast-%j.out  # %j = job ID\n",
    "\n",
    "module load conda/latest\n",
    "conda activate assembly\n",
    "\n",
    "SAMPLENAME=\"pstr\"\n",
    "WORKDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}/megahit_assembly\"\n",
    "OUTDIR=\"/work/pi_sarah_gignouxwolfsohn_uml_edu/nikea/COL/assembly/${SAMPLENAME}\"\n",
    "\n",
    "metaquast \"$WORKDIR\"/\"$SAMPLENAME\".contigs.fa -t 12 -o $OUTDIR/quast_output\n",
    "\n",
    "# Job ID: \n",
    "# bash script file name: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6eb53-26f8-4603-be6f-8ee6d67e13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing files that aren't needed\n",
    "rm -r krona_charts quast_downloaded_references runs_per_reference icarus_viewers summary/TEX summary/TSV combined_reference/icarus_viewers combined_reference/aligned_stats\n",
    "rm combined_reference/*.tex combined_reference/*.tsv\n",
    "rm not_aligned/*.tex not_aligned/*.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f597fd7-1a77-4ef3-b2e3-cdf1800e9c73",
   "metadata": {},
   "source": [
    "download /not_aligned/report.html/pdf for basic stats and moved /host_removed and /final_reads_filtered to project folder. \n",
    "\n",
    "Just keeping the /repaired reads for mapping step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
